{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from dtw import dtw\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pickle\n",
    "import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from dtw import dtw\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pickle\n",
    "import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "PRE_NAME = \"onemin_ohlc_\"\n",
    "BEGIN_TIME = \"09:00:00\"\n",
    "END_TIME = \"11:00:00\"\n",
    "NUM_CLUSTER = 50\n",
    "def load_data(date_begin='20180612', date_end = '20180928', split_date_begin = '20181001', split_date_end = '20181031', train = True):\n",
    "    X = []\n",
    "    Y = []\n",
    "    # df = pd.read_csv(os.path.join('dataset', '2327', PRE_NAME+\"20180612.csv\"))\n",
    "    # mask = (df.loc[:, \"time\"] >= BEGIN_TIME) & (df.loc[:, \"time\"] <= END_TIME)\n",
    "    # front_df = df[mask].loc[:, \"return\"]\n",
    "    # end_df = df[~mask].loc[:, \"return\"]\n",
    "    # X.append(np.array(front_df))\n",
    "    # Y.append(np.array(end_df))\n",
    "    # \"\"\"我是分隔線^^~\"\"\"\n",
    "    # df = pd.read_csv(os.path.join('dataset', '2327', PRE_NAME+\"20180613.csv\"))\n",
    "    # mask = (df.loc[:, \"time\"] >= BEGIN_TIME) & (df.loc[:, \"time\"] <= END_TIME)\n",
    "    # front_df = df[mask].loc[:, \"return\"]\n",
    "    # end_df = df[~mask].loc[:, \"return\"]\n",
    "    # X.append(np.array(front_df))\n",
    "    # Y.append(np.array(end_df))\n",
    "    \n",
    "    for sid in tqdm(os.listdir(os.path.join('dataset'))):\n",
    "        for file in os.listdir(os.path.join('dataset', sid)):\n",
    "            curday = file[12:20]\n",
    "            if (train == True and curday <= date_end and curday >= date_begin) or (train == False and curday >= split_date_begin and curday <= split_date_end):\n",
    "                df = pd.read_csv(os.path.join('dataset', sid, file))\n",
    "                df = df\n",
    "                mask = (df.loc[:, \"time\"] >= BEGIN_TIME) & (df.loc[:, \"time\"] <= END_TIME)\n",
    "                front_df = df[mask].loc[:, \"return\"]\n",
    "                front_df = front_df.take(np.arange(0, len(front_df), 5))\n",
    "                end_df = df[~mask].loc[:, \"return\"]\n",
    "                if len(front_df) == (121 // 5 +1):\n",
    "                    X.append(np.array(front_df))\n",
    "                    Y.append(np.array(end_df))\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def dtw_d(X, Y):\n",
    "    manhattan_distance = lambda x, y: np.abs(x - y)\n",
    "    d, cost_matrix, acc_cost_matrix, path = dtw(X, Y, dist=manhattan_distance)\n",
    "    return d\n",
    "\n",
    "def dtw_affinity(X):\n",
    "    return pairwise_distances(X, metric=dtw_d)\n",
    "\n",
    "def fastdtw_d(X, Y):\n",
    "    return fastdtw(X, Y, dist=euclidean)[0]\n",
    "\n",
    "\n",
    "def fastdtw_d2(X, Y):\n",
    "    manhattan_distance = lambda x, y: np.abs(x - y)\n",
    "    return fastdtw(X, Y, dist=manhattan_distance)[0]\n",
    "\n",
    "def fastdtw_affinity(X):\n",
    "    return pairwise_distances(X, metric=fastdtw_d)\n",
    "\n",
    "def fastdtw_affinity2(X):\n",
    "    return pairwise_distances(X, metric=fastdtw_d2)\n",
    "\n",
    "\n",
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 25)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194.86116576194763\n",
      "0.0\n",
      "119.6130588054657\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "dtw_affinity(X)\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n",
    "t1 = time.time()\n",
    "fastdtw_affinity(X)\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n",
    "fastdtw_affinity2(X)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 17.71it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = load_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 25)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 25)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.29491754 0.19423883 ... 0.7680259  0.65996781 1.60347366]\n",
      " [0.29491754 0.         0.46316372 ... 0.61322597 0.46987373 1.34052175]\n",
      " [0.19423883 0.46316372 0.         ... 1.05037046 0.96292973 1.98140097]\n",
      " ...\n",
      " [0.7680259  0.61322597 1.05037046 ... 0.         0.12858263 1.03331465]\n",
      " [0.65996781 0.46987373 0.96292973 ... 0.12858263 0.         0.97961483]\n",
      " [1.60347366 1.34052175 1.98140097 ... 1.03331465 0.97961483 0.        ]]\n",
      "time: 193.71122932434082\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(dtw_affinity(X))\n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.29491754 0.22588733 ... 0.7680259  0.6666947  1.60347366]\n",
      " [0.29491754 0.         0.46316372 ... 0.61548866 0.46987373 1.34052175]\n",
      " [0.22588733 0.46316372 0.         ... 1.05669155 0.96292973 1.98785477]\n",
      " ...\n",
      " [0.7680259  0.61548866 1.05669155 ... 0.         0.17195164 1.03331465]\n",
      " [0.6666947  0.46987373 0.96292973 ... 0.17195164 0.         0.97961483]\n",
      " [1.60347366 1.34052175 1.98785477 ... 1.03331465 0.97961483 0.        ]]\n",
      "time: 418.2504553794861\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(fastdtw_affinity(X))\n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "dbs = DBSCAN(min_samples=40, metric=fastdtw_d, n_jobs = 6)\n",
    "X_label = dbs.fit_predict(X)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "dbs = DBSCAN(min_samples=40, metric=dtw_d, n_jobs = 6)\n",
    "X_label = dbs.fit_predict(X)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "dbs = DBSCAN(min_samples=40, n_jobs = 6)\n",
    "X_label = dbs.fit_predict(X)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(NUM_CLUSTER):\n",
    "    for i in range(len(X)):\n",
    "    #     plt.subplot(10, 1, X_label[i]+1)\n",
    "        if X_label[i] == n:\n",
    "            plt.plot(X[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_long_simple(y, cost):\n",
    "    return y.max() - y[0] - cost\n",
    "def make_short_simple(y, cost):\n",
    "    return y[0] - y.min() - cost\n",
    "def make_long_max_lost(y, cost):\n",
    "    return y.min() - y[0] - cost\n",
    "def make_short_max_lost(y, cost):\n",
    "    return y[0] - y.max() - cost\n",
    "def make_long(y, cost, exp_profit):\n",
    "    if np.sum(y-y[0]-cost >= exp_profit):\n",
    "        return exp_profit\n",
    "    else:\n",
    "        return y[-1] - y[0] - cost\n",
    "\n",
    "def make_short(y, cost, exp_profit):\n",
    "    if np.sum(y[0]-y-cost >= exp_profit):\n",
    "        return exp_profit\n",
    "    else:\n",
    "        return -y[-1] + y[0] - cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eb187a6c66b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mX_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_label\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X_DBSCAN_tabel.pk\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "def make_table(X, X_label):\n",
    "    X_mean = np.zeros((len(X_label), len(X[0])))\n",
    "    for i in range(NUM_CLUSTER):\n",
    "        X_mean[X_label[i]] = X[X_label==i].mean(axis=0)\n",
    "    return X_mean\n",
    "X_table = make_table(X, X_label)\n",
    "pickle.dump(X_tabel, open(\"X_DBSCAN_tabel.pk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_long_array = np.zeros(NUM_CLUSTER)\n",
    "profit_short_array = np.zeros(NUM_CLUSTER)\n",
    "lost_long_array = np.zeros(NUM_CLUSTER)\n",
    "lost_short_array = np.zeros(NUM_CLUSTER)\n",
    "num_long_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "num_short_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "for i in range(len(X)):\n",
    "    profit_long_array[X_label[i]] += make_long_simple(Y[i], 0.002)\n",
    "    profit_short_array[X_label[i]] += make_short_simple(Y[i], 0.002)\n",
    "    lost_long_array[X_label[i]] += make_long_max_lost(Y[i], 0.002)\n",
    "    lost_short_array[X_label[i]] += make_short_max_lost(Y[i], 0.002)\n",
    "    num_long_array[X_label[i]] += 1\n",
    "    num_short_array[X_label[i]] += 1\n",
    "print(profit_long_array)\n",
    "print(profit_short_array)\n",
    "print(lost_long_array)\n",
    "print(lost_short_array)\n",
    "print(num_long_array)\n",
    "print(num_short_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ac, open(\"ac_model2.pc\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = pickle.load(open(\"ac_model2.pc\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_l_p = ac.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_label = x_l_p\n",
    "for n in range(NUM_CLUSTER):\n",
    "    for i in range(len(X)):\n",
    "    #     plt.subplot(10, 1, X_label[i]+1)\n",
    "        if X_label[i] == n:\n",
    "            plt.plot(X[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_long_array = np.zeros(NUM_CLUSTER)\n",
    "profit_short_array = np.zeros(NUM_CLUSTER)\n",
    "lost_long_array = np.zeros(NUM_CLUSTER)\n",
    "lost_short_array = np.zeros(NUM_CLUSTER)\n",
    "num_long_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "num_short_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "for i in range(len(X)):\n",
    "    profit_long_array[X_label[i]] += make_long_simple(Y[i], 0.002)\n",
    "    profit_short_array[X_label[i]] += make_short_simple(Y[i], 0.002)\n",
    "    lost_long_array[X_label[i]] += make_long_max_lost(Y[i], 0.002)\n",
    "    lost_short_array[X_label[i]] += make_short_max_lost(Y[i], 0.002)\n",
    "    num_long_array[X_label[i]] += 1\n",
    "    num_short_array[X_label[i]] += 1\n",
    "print('best avg long return',sorted(profit_long_array/num_long_array)[::-1][:10])\n",
    "print('best avg short return' ,sorted(profit_short_array/num_short_array)[::-1][:10])\n",
    "print('worst avg long return', sorted(lost_long_array/num_long_array)[::-1][:10])\n",
    "print('worst avg short return', sorted(lost_short_array/num_short_array)[::-1][:10])\n",
    "print(num_long_array)\n",
    "print(num_short_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster(X, X_table):\n",
    "    prev_min = dtw_d(X, X_table[0])\n",
    "    prev_min_arg = 0\n",
    "    for i in range(1, NUM_CLUSTER):\n",
    "        cur_min = dtw_d(X, X_table[i])\n",
    "        if prev_min >= cur_min:\n",
    "            prev_min = cur_min\n",
    "            prev_min_arg = i\n",
    "    return prev_min_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_cluster(X_test[0], X_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_long_array = np.zeros(NUM_CLUSTER)\n",
    "profit_short_array = np.zeros(NUM_CLUSTER)\n",
    "lost_long_array = np.zeros(NUM_CLUSTER)\n",
    "lost_short_array = np.zeros(NUM_CLUSTER)\n",
    "num_long_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "num_short_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "for i in range(len(X)):\n",
    "    profit_long_array[X_label[i]] += make_long(Y[i], 0.002, 0.025)\n",
    "    profit_short_array[X_label[i]] += make_short(Y[i], 0.002, 0.025)\n",
    "    num_long_array[X_label[i]] += 1\n",
    "    num_short_array[X_label[i]] += 1\n",
    "print('avg long return',sorted(profit_long_array/num_long_array)[::-1][:10])\n",
    "print('avg short return' ,sorted(profit_short_array/num_short_array)[::-1][:10])\n",
    "print(num_long_array)\n",
    "print(num_short_array)\n",
    "best_long_cluster = np.argsort(profit_long_array/num_long_array)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_long_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_test, Y_test, X_table):\n",
    "    profit_long_array = np.zeros(NUM_CLUSTER)\n",
    "    profit_short_array = np.zeros(NUM_CLUSTER)\n",
    "    lost_long_array = np.zeros(NUM_CLUSTER)\n",
    "    lost_short_array = np.zeros(NUM_CLUSTER)\n",
    "    num_long_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "    num_short_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "    X_label = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "    for i in range(len(X_test)):\n",
    "        X_label = find_cluster(X_test[i], X_table)\n",
    "        profit_long_array[X_label] += make_long(Y_test[i], 0.002, 0.025)\n",
    "        profit_short_array[X_label] += make_short(Y_test[i], 0.002, 0.025)\n",
    "        num_long_array[X_label] += 1\n",
    "        num_short_array[X_label] += 1\n",
    "        \n",
    "        \n",
    "    print('avg long return',sorted(profit_long_array/num_long_array)[::-1][:10])\n",
    "    print('avg short return' ,sorted(profit_short_array/num_short_array)[::-1][:10])\n",
    "    print(num_long_array)\n",
    "    print(num_short_array)\n",
    "    return profit_long_array, profit_short_array, num_long_array \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_long_array, profit_short_array, num_long_array  = evaluate(X_test, Y_test, X_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_CLUSTER):\n",
    "    print(i, profit_long_array[i], num_long_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_long_cluster = np.argsort(profit_long_array/num_long_array)\n",
    "for n in range(10):\n",
    "    for i in range(len(X)):\n",
    "    #     plt.subplot(10, 1, X_label[i]+1)\n",
    "        if X_label[i] == n:\n",
    "            plt.plot(X[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
