{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|▊         | 1/13 [00:01<00:14,  1.19s/it]\u001b[A\n",
      " 15%|█▌        | 2/13 [00:02<00:13,  1.19s/it]\u001b[A\n",
      " 23%|██▎       | 3/13 [00:03<00:11,  1.18s/it]\u001b[A\n",
      " 31%|███       | 4/13 [00:04<00:10,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 5/13 [00:05<00:09,  1.14s/it]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:06<00:07,  1.13s/it]\u001b[A\n",
      " 54%|█████▍    | 7/13 [00:07<00:06,  1.13s/it]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:09<00:05,  1.13s/it]\u001b[A\n",
      " 69%|██████▉   | 9/13 [00:10<00:04,  1.12s/it]\u001b[A\n",
      " 77%|███████▋  | 10/13 [00:11<00:03,  1.12s/it]\u001b[A\n",
      " 85%|████████▍ | 11/13 [00:12<00:02,  1.12s/it]\u001b[A\n",
      " 92%|█████████▏| 12/13 [00:13<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 13/13 [00:14<00:00,  1.13s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from dtw import dtw\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pickle\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "PRE_NAME = \"onemin_ohlc_\"\n",
    "BEGIN_TIME = \"09:00:00\"\n",
    "END_TIME = \"10:30:00\"\n",
    "NUM_CLUSTER = 50\n",
    "TIME_STEP = 5\n",
    "def load_data(date_begin='20180612', date_end = '20200301', split_date_begin = '20200302', split_date_end = '20200915', train = True):\n",
    "    X = []\n",
    "    Y = []\n",
    "    h1, m1, s1 = [int(x) for x in BEGIN_TIME.split(\":\")]\n",
    "    h2, m2, s2 = [int(x) for x in END_TIME.split(\":\")]\n",
    "    t1 = dt.timedelta(hours = h1, minutes=m1)\n",
    "    t2 = dt.timedelta(hours = h2, minutes=m2)\n",
    "    total_mins = (t2-t1).total_seconds()//60\n",
    "    \n",
    "    \n",
    "    for sid in tqdm(os.listdir(os.path.join('dataset'))):\n",
    "        for file in os.listdir(os.path.join('dataset', sid)):\n",
    "            curday = file[12:20]\n",
    "            if (train == True and curday <= date_end and curday >= date_begin) or (train == False and curday >= split_date_begin and curday <= split_date_end):\n",
    "                df = pd.read_csv(os.path.join('dataset', sid, file))\n",
    "                df = df\n",
    "                mask = (df.loc[:, \"time\"] >= BEGIN_TIME) & (df.loc[:, \"time\"] <= END_TIME)\n",
    "                front_df = df[mask].loc[:, \"return\"]\n",
    "                front_df = front_df.take(np.arange(0, len(front_df), TIME_STEP))\n",
    "                end_df = df[~mask].loc[:, \"return\"]\n",
    "                if len(front_df) == (90 // TIME_STEP +1):\n",
    "                    X.append(np.array(front_df))\n",
    "                    Y.append(np.array(end_df))\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def dtw_d(X, Y):\n",
    "    manhattan_distance = lambda x, y: np.abs(x - y)\n",
    "    d, cost_matrix, acc_cost_matrix, path = dtw(X, Y, dist=manhattan_distance)\n",
    "    return d\n",
    "\n",
    "def dtw_affinity(X):\n",
    "    return pairwise_distances(X, metric=dtw_d)\n",
    "\n",
    "def fastdtw_d(X, Y):\n",
    "    return fastdtw(X, Y, dist=euclidean)[0]\n",
    "\n",
    "def fastdtw_affinity(X):\n",
    "    return pairwise_distances(X, metric=fastdtw_d)\n",
    "\n",
    "\n",
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|▊         | 1/13 [00:00<00:04,  2.64it/s]\u001b[A\n",
      " 15%|█▌        | 2/13 [00:00<00:04,  2.64it/s]\u001b[A\n",
      " 23%|██▎       | 3/13 [00:01<00:03,  2.61it/s]\u001b[A\n",
      " 31%|███       | 4/13 [00:01<00:03,  2.61it/s]\u001b[A\n",
      " 38%|███▊      | 5/13 [00:01<00:03,  2.61it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:02<00:02,  2.63it/s]\u001b[A\n",
      " 54%|█████▍    | 7/13 [00:02<00:02,  2.65it/s]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:03<00:01,  2.59it/s]\u001b[A\n",
      " 69%|██████▉   | 9/13 [00:03<00:01,  2.62it/s]\u001b[A\n",
      " 77%|███████▋  | 10/13 [00:03<00:01,  2.64it/s]\u001b[A\n",
      " 85%|████████▍ | 11/13 [00:04<00:00,  2.66it/s]\u001b[A\n",
      " 92%|█████████▏| 12/13 [00:04<00:00,  2.68it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:04<00:00,  2.64it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = load_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2990, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(915, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1 = time.time()\n",
    "fastdtw_affinity(X)\n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)\n",
    "t1 = time.time()\n",
    "dtw_affinity(X)\n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "ac = AgglomerativeClustering(n_clusters = NUM_CLUSTER,\n",
    "                             affinity = fastdtw_affinity,\n",
    "                             linkage = 'complete')\n",
    "X_label = ac.fit_predict(X)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1 = time.time()\n",
    "ac = AgglomerativeClustering(n_clusters = NUM_CLUSTER,\n",
    "                             affinity = dtw_affinity,\n",
    "                             linkage = 'complete')\n",
    "X_label = ac.fit_predict(X)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1 = time.time()\n",
    "ac = AgglomerativeClustering(n_clusters = NUM_CLUSTER,\n",
    "                             linkage = 'complete')\n",
    "X_label = ac.fit_predict(X)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_table, open(os.path.join('dataset_pk',\"X.pk\"), \"wb\"))\n",
    "pickle.dump(X_table, open(os.path.join('dataset_pk',\"Y.pk\"), \"wb\"))\n",
    "pickle.dump(X_table, open(os.path.join('dataset_pk',\"X_tabel.pk\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(NUM_CLUSTER):\n",
    "    plt.title(n)\n",
    "    for i in range(len(X)):\n",
    "    #     plt.subplot(10, 1, X_label[i]+1)\n",
    "        if X_label[i] == n:\n",
    "            plt.plot(X[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_long_simple(y, cost):\n",
    "    return y.max() - y[0] - cost\n",
    "def make_short_simple(y, cost):\n",
    "    return y[0] - y.min() - cost\n",
    "def make_long_max_lost(y, cost):\n",
    "    return y.min() - y[0] - cost\n",
    "def make_short_max_lost(y, cost):\n",
    "    return y[0] - y.max() - cost\n",
    "def make_long(y, cost, exp_profit):\n",
    "    if (y-y[0]-cost >= exp_profit).any():\n",
    "        return exp_profit\n",
    "    else:\n",
    "        return y[-1] - y[0] - cost\n",
    "\n",
    "def make_short(y, cost, exp_profit):\n",
    "    if (y[0]-y-cost >= exp_profit).any():\n",
    "        return exp_profit\n",
    "    else:\n",
    "        return -y[-1] + y[0] - cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(X, X_label):\n",
    "    X_mean = np.zeros((len(X_label), len(X[0])))\n",
    "    for i in range(NUM_CLUSTER):\n",
    "        X_mean[X_label[i]] = X[X_label==i].mean(axis=0)\n",
    "    return X_mean\n",
    "X_table = make_table(X, X_label)\n",
    "pickle.dump(X_table, open(os.path.join('dataset_pk',\"X_tabel.pk\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_long_array = np.zeros(NUM_CLUSTER)\n",
    "profit_short_array = np.zeros(NUM_CLUSTER)\n",
    "lost_long_array = np.zeros(NUM_CLUSTER)\n",
    "lost_short_array = np.zeros(NUM_CLUSTER)\n",
    "num_long_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "num_short_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "for i in range(len(X)):\n",
    "    profit_long_array[X_label[i]] += make_long_simple(Y[i], 0.002)\n",
    "    profit_short_array[X_label[i]] += make_short_simple(Y[i], 0.002)\n",
    "    lost_long_array[X_label[i]] += make_long_max_lost(Y[i], 0.002)\n",
    "    lost_short_array[X_label[i]] += make_short_max_lost(Y[i], 0.002)\n",
    "    num_long_array[X_label[i]] += 1\n",
    "    num_short_array[X_label[i]] += 1\n",
    "print(profit_long_array)\n",
    "print(profit_short_array)\n",
    "print(lost_long_array)\n",
    "print(lost_short_array)\n",
    "print(num_long_array)\n",
    "print(num_short_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ac, open(\"ac_model2.pc\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = pickle.load(open(\"ac_model2.pc\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_long_array = np.zeros(NUM_CLUSTER)\n",
    "profit_short_array = np.zeros(NUM_CLUSTER)\n",
    "lost_long_array = np.zeros(NUM_CLUSTER)\n",
    "lost_short_array = np.zeros(NUM_CLUSTER)\n",
    "num_long_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "num_short_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "for i in range(len(X)):\n",
    "    profit_long_array[X_label[i]] += make_long_simple(Y[i], 0.002)\n",
    "    profit_short_array[X_label[i]] += make_short_simple(Y[i], 0.002)\n",
    "    lost_long_array[X_label[i]] += make_long_max_lost(Y[i], 0.002)\n",
    "    lost_short_array[X_label[i]] += make_short_max_lost(Y[i], 0.002)\n",
    "    num_long_array[X_label[i]] += 1\n",
    "    num_short_array[X_label[i]] += 1\n",
    "print('best avg long return',sorted(profit_long_array/num_long_array)[::-1][:10])\n",
    "print('best avg short return' ,sorted(profit_short_array/num_short_array)[::-1][:10])\n",
    "print('worst avg long return', sorted(lost_long_array/num_long_array)[::-1][:10])\n",
    "print('worst avg short return', sorted(lost_short_array/num_short_array)[::-1][:10])\n",
    "print(num_long_array)\n",
    "print(num_short_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster(X, X_table):\n",
    "    prev_min = dtw_d(X, X_table[0])\n",
    "    prev_min_arg = 0\n",
    "    for i in range(1, NUM_CLUSTER):\n",
    "        cur_min = dtw_d(X, X_table[i])\n",
    "        if prev_min >= cur_min:\n",
    "            prev_min = cur_min\n",
    "            prev_min_arg = i\n",
    "    return prev_min_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster_L2(X, X_table):\n",
    "    prev_min = dtw_d(X, X_table[0])\n",
    "    prev_min_arg = 0\n",
    "    for i in range(1, NUM_CLUSTER):\n",
    "        cur_min = np.sum((X - X_table[i])**2)\n",
    "        if prev_min >= cur_min:\n",
    "            prev_min = cur_min\n",
    "            prev_min_arg = i\n",
    "    return prev_min_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_cluster_L2(X_test[0], X_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_long_array = np.zeros(NUM_CLUSTER)\n",
    "profit_short_array = np.zeros(NUM_CLUSTER)\n",
    "lost_long_array = np.zeros(NUM_CLUSTER)\n",
    "lost_short_array = np.zeros(NUM_CLUSTER)\n",
    "num_long_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "num_short_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "for i in range(len(X)):\n",
    "    profit_long_array[X_label[i]] += make_long(Y[i], 0.002, 0.025)\n",
    "    profit_short_array[X_label[i]] += make_short(Y[i], 0.002, 0.025)\n",
    "    num_long_array[X_label[i]] += 1\n",
    "    num_short_array[X_label[i]] += 1\n",
    "print('avg long return',sorted(profit_long_array/num_long_array)[::-1][:10])\n",
    "print('avg short return' ,sorted(profit_short_array/num_short_array)[::-1][:10])\n",
    "print(num_long_array)\n",
    "print(num_short_array)\n",
    "best_long_cluster = np.argsort(profit_long_array/num_long_array)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_long_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_test, Y_test, X_table, exp_profit=0.025):\n",
    "    profit_long_array = np.zeros(NUM_CLUSTER)\n",
    "    profit_short_array = np.zeros(NUM_CLUSTER)\n",
    "    lost_long_array = np.zeros(NUM_CLUSTER)\n",
    "    lost_short_array = np.zeros(NUM_CLUSTER)\n",
    "    num_exchange_array = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "    X_label = np.zeros(NUM_CLUSTER).astype(\"int\")\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        X_label = find_cluster(X_test[i], X_table)\n",
    "        # profit_long_array[X_label] += make_long(Y_test[i], 0.002, exp_profit)\n",
    "        profit_short_array[X_label] += make_short(Y_test[i], 0.002, exp_profit)\n",
    "        num_exchange_array[X_label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_long_array, profit_short_array, num_long_array  = evaluate(X_test, Y_test, X_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(best_long_cluster)):\n",
    "    print(i, profit_long_array[best_long_cluster[i]], num_long_array[best_long_cluster[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_long_cluster = np.argsort(profit_long_array/num_long_array)[::-1]\n",
    "for n in range(10):\n",
    "    for i in range(len(X)):\n",
    "    #     plt.subplot(10, 1, X_label[i]+1)\n",
    "        if X_label[i] == n:\n",
    "            plt.plot(X[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
